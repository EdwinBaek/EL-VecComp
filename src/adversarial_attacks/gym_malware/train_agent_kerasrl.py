"""
adversarial_malware_samples/
    └── 20241023_235959/           # Timestamp based run
        ├── samples/               # input samples
        ├── generated_samples/     # Generated adversarial samples
        ├── models/                # Saved DQN model
        └── logs/                  # Training logs and statistics
"""

import pickle
import numpy as np
import gym
import os
from datetime import datetime

np.random.seed(123)
import gym_malware

from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, ELU, Dropout, BatchNormalization
from keras.optimizers import Adam, SGD, RMSprop

from rl.agents.dqn import DQNAgent
from rl.policy import BoltzmannQPolicy
from rl.memory import SequentialMemory


class MalwareAdversarialGenerator:
    def __init__(self, output_base_path="adversarial_samples"):
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_base_path = output_base_path
        self.setup_directories()

    def setup_directories(self):
        """Setup output directories for adversarial samples and logs"""
        self.run_path = os.path.join(self.output_base_path, self.timestamp)
        self.sample_path = os.path.join(self.run_path, "samples")
        self.generated_sample_path = os.path.join(self.run_path, "generated_samples")
        self.model_path = os.path.join(self.run_path, "models")
        self.log_path = os.path.join(self.run_path, "logs")

        for path in [self.sample_path, self.model_path, self.log_path]:
            os.makedirs(path, exist_ok=True)

    def generate_dense_model(self, input_shape, layers, nb_actions):
        model = Sequential()
        model.add(Flatten(input_shape=input_shape))
        model.add(Dropout(0.1))

        for layer in layers:
            model.add(Dense(layer))
            model.add(BatchNormalization())
            model.add(ELU(alpha=1.0))

        model.add(Dense(nb_actions))
        model.add(Activation('linear'))
        print(model.summary())
        return model

    def train_dqn_model(self, layers, rounds=10000, run_test=False, use_score=False):
        """Train DQN model and generate adversarial samples"""
        # Setup environment
        ENV_NAME = 'malware-score-v0' if use_score else 'malware-v0'
        env = gym.make(ENV_NAME)
        env.seed(2024)

        # Configure environment to use our custom output path
        env.output_path = self.generated_sample_path

        nb_actions = env.action_space.n
        window_length = 1

        # Create model and agent
        model = self.generate_dense_model((window_length,) + env.observation_space.shape, layers, nb_actions)
        policy = BoltzmannQPolicy()
        memory = SequentialMemory(limit=32, window_length=window_length)

        agent = DQNAgent(
            model=model,
            nb_actions=nb_actions,
            memory=memory,
            nb_steps_warmup=16,
            enable_double_dqn=True,
            enable_dueling_network=True,
            dueling_type='avg',
            target_model_update=1e-2,
            policy=policy,
            batch_size=16
        )
        agent.compile(RMSprop(lr=1e-3), metrics=['mae'])

        # Train the agent
        training_history = agent.fit(env, nb_steps=rounds, visualize=False, verbose=2)

        # Save training results
        model.save(os.path.join(self.model_path, 'dqn_model.h5'))

        # Save training history and statistics
        stats = {
            'training_history': training_history.history,
            'total_samples': len(os.listdir(self.sample_path)),
            'training_rounds': rounds,
            'timestamp': self.timestamp
        }

        with open(os.path.join(self.log_path, 'training_stats.pkl'), 'wb') as f:
            pickle.dump(stats, f)

        history_test = None
        if run_test:
            # Set up the testing environment
            TEST_NAME = 'malware-score-test-v0' if use_score else 'malware-test-v0'
            test_env = gym.make(TEST_NAME)

            # evaluate the agent on a few episodes, drawing randomly from the test samples
            agent.test(test_env, nb_episodes=100, visualize=False)
            history_test = test_env.history
        with open('history_score.pickle', 'wb') as f:
            pickle.dump(history_test, f, pickle.HIGHEST_PROTOCOL)

        # Generate summary report
        self.generate_summary_report(stats)

        return agent, model, env.history

    def generate_summary_report(self, stats):
        """Generate a human-readable summary report"""
        report = f"""
        Adversarial Malware Generation Report
        ====================================
        Timestamp: {self.timestamp}
        Total Training Rounds: {stats['training_rounds']}
        Successfully Generated Samples: {stats['total_samples']}
        Success Rate: {(stats['total_samples'] / stats['training_rounds']) * 100:.2f}%

        Output Locations:
        - Adversarial Input Samples: {self.sample_path}
        - Adversarial Generated Samples: {self.generated_sample_path}
        - Trained Model: {self.model_path}
        - Training Logs: {self.log_path}
        """

        with open(os.path.join(self.log_path, 'summary_report.txt'), 'w') as f:
            f.write(report)

        print(report)


if __name__ == '__main__':
    generator = MalwareAdversarialGenerator(output_base_path="adversarial_malware_samples")
    agent, model, history = generator.train_dqn_model([1024, 256], rounds=50000, run_test=True, use_score=False)